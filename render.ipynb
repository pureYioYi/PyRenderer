{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16104/2786641139.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  RT = torch.tensor(RT)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No mesh interpreter found to read data/gearbox/BASE.stl.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 115\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m# pytorch 3D\u001b[39;00m\n\u001b[1;32m    114\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m mesh \u001b[39m=\u001b[39m IO()\u001b[39m.\u001b[39;49mload_mesh(obj_filename)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    116\u001b[0m mesh\u001b[39m.\u001b[39mscale_verts_(\u001b[39m0.001\u001b[39m)\n\u001b[1;32m    117\u001b[0m meshes \u001b[39m=\u001b[39m mesh\u001b[39m.\u001b[39mextend(vps)\n",
      "File \u001b[0;32m~/SDKs/Python/Anaconda/envs/p3d/lib/python3.9/site-packages/pytorch3d/io/pluggable.py:138\u001b[0m, in \u001b[0;36mIO.load_mesh\u001b[0;34m(self, path, include_textures, device, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[39mif\u001b[39;00m mesh \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m         \u001b[39mreturn\u001b[39;00m mesh\n\u001b[0;32m--> 138\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo mesh interpreter found to read \u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No mesh interpreter found to read data/gearbox/BASE.stl."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from utils import *\n",
    "\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.io import IO\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    look_at_rotation,\n",
    "    OpenGLPerspectiveCameras,\n",
    "    PerspectiveCameras,\n",
    "    PointLights,\n",
    "    DirectionalLights,\n",
    "    AmbientLights,\n",
    "    RasterizationSettings,\n",
    "    MeshRenderer,\n",
    "    MeshRasterizer,\n",
    "    SoftPhongShader,\n",
    "    SoftSilhouetteShader,\n",
    "    TexturesVertex,\n",
    "    BlendParams,\n",
    ")\n",
    "\n",
    "from RasterModel.rastermodel import RaseterObjectModel, UoM\n",
    "from RasterModel.view_points import sample_views\n",
    "\n",
    "def concat_R_T(R, T):\n",
    "    n = R.shape[0]\n",
    "    R = torch.tensor(R)\n",
    "    T = torch.tensor(T)\n",
    "\n",
    "    RT = torch.zeros((n, 4, 4))\n",
    "    RT[:, 3, 3] = 1\n",
    "    RT[:, :3, :3] = R\n",
    "    RT[:, :3, 3] = T\n",
    "    return RT\n",
    "\n",
    "def convert_bop_pose_to_p3d(RT):\n",
    "    Rz = torch.tensor([[-1, 0, 0, 0], [0, -1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]).float()\n",
    "    RT = torch.tensor(RT)\n",
    "    RT = torch.matmul(Rz, RT)\n",
    "\n",
    "    n = RT.shape[0]\n",
    "    Rs = torch.zeros((n, 3, 3))\n",
    "    Ts = torch.zeros((n, 3))\n",
    "\n",
    "    for i in range(n):\n",
    "        Rs[i] = RT[i, :3, :3].t()\n",
    "        Ts[i] = RT[i, :3, 3]\n",
    "\n",
    "    return Rs, Ts\n",
    "\n",
    "def convert_bop_cam_to_p3d(R, T, K, w, h, b, device):\n",
    "    f_x, f_y = K[0, 0], K[1, 1]\n",
    "    p_x, p_y = K[0, 2], K[1, 2]\n",
    "    f = torch.tensor((f_x, f_y), dtype=torch.float32).unsqueeze(0)\n",
    "    p = torch.tensor((p_x, p_y), dtype=torch.float32).unsqueeze(0)\n",
    "    # img_size = torch.tensor((h, w), dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    camera = PerspectiveCameras(\n",
    "        R=R, T=T, focal_length=f, principal_point=p, image_size=((h, w),), device=device, in_ndc=False\n",
    "    )\n",
    "    return camera\n",
    "\n",
    "def sample_viewpoints_p3d(n, r):\n",
    "    elev = torch.linspace(0, 360, n)\n",
    "    azim = torch.linspace(-180, 180, n)\n",
    "    R, T = look_at_view_transform(dist = r, elev = elev, azim = azim) \n",
    "    return R, T\n",
    "\n",
    "def sample_viewpoints_bop(n, r):\n",
    "    vps, _ = sample_views(n, r, mode='fibonacci')\n",
    "    R = np.zeros((n,3,3))\n",
    "    T = np.zeros((n,3))\n",
    "\n",
    "    for i in range(n):\n",
    "        R[i] = vps[i]['R']\n",
    "        T[i] = vps[i]['t'].reshape(3,)\n",
    "\n",
    "    return R, T\n",
    "\n",
    "\n",
    "\n",
    "# Params\n",
    "K = np.array([[572.4114, 0.0, 325.2611], [0.0, 573.57043, 242.04899], [0.0, 0.0, 1.0]])\n",
    "\n",
    "f_x, f_y = K[0, 0], K[1, 1]\n",
    "p_x, p_y = K[0, 2], K[1, 2]\n",
    "h = 480\n",
    "w = 640\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Pose\n",
    "vps = 16\n",
    "# R, T = sample_viewpoints_p3d(vps, 0.3) #[16,3,3] and [16,3]\n",
    "R, T = sample_viewpoints_bop(vps, 0.3)\n",
    "RT = concat_R_T(R, T)\n",
    "R, T = convert_bop_pose_to_p3d(RT)\n",
    "\n",
    "# obj_filename = 'data/lm_models/obj_000001.ply'\n",
    "obj_filename = 'data/gearbox/BASE.stl'\n",
    "\n",
    "# pytorch 3D\n",
    "device = torch.device(\"cuda:0\")\n",
    "mesh = IO().load_mesh(obj_filename).to(device)\n",
    "mesh.scale_verts_(0.001)\n",
    "meshes = mesh.extend(vps)\n",
    "camera = convert_bop_cam_to_p3d(R,T,K,w,h,vps,device)\n",
    "lights = AmbientLights(device=device)\n",
    "blend_params = BlendParams(sigma=1e-4, gamma=1e-4, background_color=(0.0, 0.0, 0.0))\n",
    "# Set Renderer Parameters\n",
    "raster_settings = RasterizationSettings(\n",
    "    image_size=(h, w),\n",
    "    blur_radius=0.0,\n",
    "    faces_per_pixel=1,\n",
    "    max_faces_per_bin=mesh.faces_packed().shape[0],\n",
    "    perspective_correct=True,\n",
    ")\n",
    "\n",
    "rasterizer = MeshRasterizer(cameras=camera, raster_settings=raster_settings)\n",
    "\n",
    "renderer = MeshRenderer(\n",
    "    rasterizer,\n",
    "    shader=SoftPhongShader(\n",
    "        device=device,\n",
    "        cameras=camera,\n",
    "        lights=lights,\n",
    "        blend_params=blend_params,\n",
    "    ),\n",
    ")\n",
    "\n",
    "p3d_images = renderer(meshes, cameras=camera, lights=lights)\n",
    "\n",
    "# raster model\n",
    "rasterModel = RaseterObjectModel(obj_filename, uom=UoM.MILLIMETER)\n",
    "rasterModel.setCamParams(K, w, h)\n",
    "\n",
    "edge_maps = np.zeros((vps, h, w, 3))\n",
    "\n",
    "for i in range(vps):\n",
    "    edge_map = p3d_images[i, :, :, :3].cpu().numpy()\n",
    "\n",
    "    # r, t = R[i].cpu().numpy(), T[i].cpu().numpy().reshape(3,-1)/1000\n",
    "    pose = RT[i].cpu().numpy()\n",
    "    rasterModel.setModelView(pose)\n",
    "    edge = rasterModel.project(edge_map.copy(), (255, 255, 255))\n",
    "    edge_maps[i] = edge\n",
    "\n",
    "\n",
    "# Plot the rendered images\n",
    "image_grid(edge_maps, rows=int(np.sqrt(vps)), cols=int(np.sqrt(vps)), rgb=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
